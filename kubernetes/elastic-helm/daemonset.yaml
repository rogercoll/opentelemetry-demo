mode: daemonset
presets:
  logsCollection:
    enabled: true
  hostMetrics:
    enabled: true
  kubeletMetrics:
    enabled: true
  kubernetesAttributes:
    enabled: true

image:
  repository: docker.elastic.co/beats/elastic-agent
  tag: 8.16.0-SNAPSHOT

securityContext:
  runAsUser: 0
  runAsGroup: 0

extraEnvs:
  # Work around for open /mounts error: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/35990
  - name: HOST_PROC_MOUNTINFO
    value: ""
  - name: ELASTIC_AGENT_OTEL
    value: "true"
  - name: ELASTIC_ENDPOINT
    valueFrom:
      secretKeyRef:
        name: elastic-secret-otel
        key: elastic_endpoint
  - name: ELASTIC_API_KEY
    valueFrom:
      secretKeyRef:
        name: elastic-secret-otel
        key: elastic_api_key
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

# kubeletstats additional rules for Node metrics
clusterRole:
  create: true
  rules:
    - apiGroups:
        - ""
      resources:
        - nodes/proxy
      verbs:
        - get
    - apiGroups:
        - ""
      resources:
        - nodes
      verbs:
        - get
        - watch
        - list

config:
  extensions:
    health_check:
      endpoint: ${env:MY_POD_IP}:13133
  exporters:
    debug:
      verbosity: basic
    elasticsearch/ecs:
      endpoints:
      - ${env:ELASTIC_ENDPOINT}
      api_key: ${env:ELASTIC_API_KEY}
      logs_dynamic_index:
        enabled: true
      metrics_dynamic_index:
        enabled: true
      mapping:
        mode: ecs
    elasticsearch/otel:
      endpoints:
      - ${env:ELASTIC_ENDPOINT}
      api_key: ${env:ELASTIC_API_KEY}
      logs_dynamic_index:
        enabled: true
      metrics_dynamic_index:
        enabled: true
      mapping:
        mode: otel
  processors:
    batch: {}
    elasticinframetrics:
      add_system_metrics: true
      add_k8s_metrics: true
      drop_original: true
    resourcedetection/cluster:
      detectors: [env, eks, gcp, aks, eks, k8snode]
      timeout: 15s
      override: true
      k8snode:
        auth_type: serviceAccount
      eks:
        resource_attributes:
          k8s.cluster.name:
            enabled: true
      aks:
        resource_attributes:
          k8s.cluster.name:
            enabled: true
    resource/k8s: # Resource attributes tailored for services within Kubernetes.
      attributes:
        - key: service.name # Set the service.name resource attribute based on the well-known app.kubernetes.io/name label
          from_attribute: app.label.name
          action: insert
        - key: service.name # Set the service.name resource attribute based on the k8s.container.name attribute
          from_attribute: k8s.container.name
          action: insert
        - key: app.label.name # Delete app.label.name attribute previously used for service.name
          action: delete
        - key: service.version # Set the service.version resource attribute based on the well-known app.kubernetes.io/version label
          from_attribute: app.label.version
          action: insert
        - key: app.label.version # Delete app.label.version attribute previously used for service.version
          action: delete
    resource/hostname:
      attributes:
        - key: host.name
          from_attribute: k8s.node.name
          action: upsert
    attributes/dataset:
      actions:
        - key: event.dataset
          from_attribute: data_stream.dataset
          action: upsert
    resource/cloud:
      attributes:
        - key: cloud.instance.id
          from_attribute: host.id
          action: insert
    resource/demo:
      attributes:
        - key: deployment.environment
          value: "opentelemetry-demo"
          action: upsert
    resource/process:
      attributes:
        - key: process.executable.name
          action: delete
        - key: process.executable.path
          action: delete
    resourcedetection/system:
      detectors: ["system", "ec2"]
      system:
        hostname_sources: [ "os" ]
        resource_attributes:
          host.name:
            enabled: true
          host.id:
            enabled: false
          host.arch:
            enabled: true
          host.ip:
            enabled: true
          host.mac:
            enabled: true
          host.cpu.vendor.id:
            enabled: true
          host.cpu.family:
            enabled: true
          host.cpu.model.id:
            enabled: true
          host.cpu.model.name:
            enabled: true
          host.cpu.stepping:
            enabled: true
          host.cpu.cache.l2.size:
            enabled: true
          os.description:
            enabled: true
          os.type:
            enabled: true
      ec2:
        resource_attributes:
          host.name:
            enabled: false
          host.id:
            enabled: true
    k8sattributes:
      filter:
        node_from_env_var: K8S_NODE_NAME
      passthrough: false
      pod_association:
        - sources:
            - from: resource_attribute
              name: k8s.pod.ip
        - sources:
            - from: resource_attribute
              name: k8s.pod.uid
        - sources:
            - from: connection
      extract:
        metadata:
          - "k8s.namespace.name"
          - "k8s.deployment.name"
          - "k8s.statefulset.name"
          - "k8s.daemonset.name"
          - "k8s.cronjob.name"
          - "k8s.job.name"
          - "k8s.node.name"
          - "k8s.pod.name"
          - "k8s.pod.uid"
          - "k8s.pod.start_time"
        labels:
          - tag_name: app.label.component
            key: app.kubernetes.io/component
            from: pod
  receivers:
    otlp: null
    jaeger: null
    prometheus: null
    zipkin: null
    filelog:
      retry_on_failure:
        enabled: true
      start_at: end
      exclude:
      # exlude collector logs
      - /var/log/pods/*/opentelemetry-collector/*.log
      include:
      - /var/log/pods/*/*/*.log
      include_file_name: false
      include_file_path: true
      operators:
      - id: container-parser
        type: container
    hostmetrics:
      collection_interval: 10s
      root_path: /hostfs
      scrapers:
        cpu:
          metrics:
            system.cpu.utilization:
              enabled: true
            system.cpu.logical.count:
              enabled: true
        memory:
          metrics:
            system.memory.utilization:
              enabled: true
        process:
          mute_process_exe_error: true
          mute_process_io_error: true
          mute_process_user_error: true
          metrics:
            process.threads:
              enabled: true
            process.open_file_descriptors:
              enabled: true
            process.memory.utilization:
              enabled: true
            process.disk.operations:
              enabled: true
        network:
        processes:
        load:
        disk:
        filesystem:
          exclude_mount_points:
            mount_points:
              - /dev/*
              - /proc/*
              - /sys/*
              - /run/k3s/containerd/*
              - /var/lib/docker/*
              - /var/lib/kubelet/*
              - /snap/*
            match_type: regexp
          exclude_fs_types:
            fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
            match_type: strict
    kubeletstats:
      auth_type: serviceAccount
      collection_interval: 20s
      endpoint: ${env:K8S_NODE_NAME}:10250
      node: '${env:K8S_NODE_NAME}'
      # Required to work for all CSPs without an issue
      insecure_skip_verify: true
      k8s_api_config:
        auth_type: serviceAccount
      metrics:
        k8s.pod.memory.node.utilization:
          enabled: true
        k8s.pod.cpu.node.utilization:
          enabled: true
        k8s.container.cpu_limit_utilization:
          enabled: true
        k8s.pod.cpu_limit_utilization:
          enabled: true
        k8s.container.cpu_request_utilization:
          enabled: true
        k8s.container.memory_limit_utilization:
          enabled: true
        k8s.pod.memory_limit_utilization:
          enabled: true
        k8s.container.memory_request_utilization:
          enabled: true
        k8s.node.uptime:
          enabled: true
        k8s.node.cpu.usage:
          enabled: true
        k8s.pod.cpu.usage:
          enabled: true
      extra_metadata_labels:
        - container.id
  service:
    extensions: [health_check]
    pipelines:
      logs:
        receivers: [filelog]
        processors: [batch, k8sattributes, resourcedetection/cluster, resource/hostname, resource/demo, resource/k8s, resource/cloud]
        exporters: [debug, elasticsearch/otel]
      metrics:
        receivers: [hostmetrics, kubeletstats]
        processors: [batch, k8sattributes, elasticinframetrics, resourcedetection/cluster, resource/hostname, resource/demo, resource/k8s, resource/cloud, attributes/dataset, resource/process]
        exporters: [debug, elasticsearch/ecs]
      metrics/otel:
        receivers: [kubeletstats]
        processors: [batch, k8sattributes, resourcedetection/cluster, resource/hostname, resource/demo, resource/k8s, resource/cloud]
        exporters: [debug, elasticsearch/otel]
      traces: null
    telemetry:
      metrics:
        address: ${env:MY_POD_IP}:8888
